How do transformer models figure out there are hidden variables affecting their environment? And how can we know for sure they’re learning the correct rules? 

In most real world RL settings, there are always hidden factors influencing outcomes that models can’t directly observe, so I’m trying to set up some simple game environments with very simple rules, training very small models in these environments, and trying to see if they can actually learn these unobservable rules / variables. 

### Ongoing Write Up
https://docs.google.com/document/d/1MjS7J9uX8nM8u2zFtZb1WNLEObFuFopXeSZHL6u21hE/edit?usp=sharing